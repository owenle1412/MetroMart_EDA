{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem is to find out the properties of a product, and store which impacts the sales \n",
    "#   of a product\n",
    "# I will explore the problem in following stages:\n",
    "# 1 Hypothesis Generation – understanding the problem better by brainstorming possible factors \n",
    "#    that can impact the outcome\n",
    "# 2 Data Exploration – looking at categorical and continuous feature summaries and making \n",
    "#    inferences about the data.\n",
    "# 3 Data Cleaning – imputing missing values in the data and checking for outliers\n",
    "# 4 Feature Engineering – modifying existing variables and creating new ones for analysis\n",
    "# 5 Model Building – making predictive models on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE HYPOTHESES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Level Hypotheses:\n",
    "# City type: Stores located in urban or Tier 1 cities should have higher sales because of \n",
    "#     the higher income levels of people there.\n",
    "# Population Density: Stores located in densely populated areas should have higher sales \n",
    "#     because of more demand.\n",
    "# Store Capacity: Stores which are very big in size should have higher sales as they act \n",
    "#     like one-stop-shops and people would prefer getting everything from one place\n",
    "# Competitors: Stores having similar establishments nearby should have less sales because \n",
    "#     of more competition.\n",
    "# Marketing: Stores which have a good marketing division should have higher sales as it will \n",
    "#     be able to attract customers through the right offers and advertising.\n",
    "# Location: Stores located within popular marketplaces should have higher sales because \n",
    "#     of better access to customers.\n",
    "# Customer Behavior: Stores keeping the right set of products to meet the local needs \n",
    "#     of customers will have higher sales.\n",
    "# Ambiance: Stores which are well-maintained and managed by polite and humble people \n",
    "#     are expected to have higher footfall and thus higher sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Product Level Hypotheses:\n",
    "# Brand: Branded products should have higher sales because of higher trust in the customer.\n",
    "# Packaging: Products with good packaging can attract customers and sell more.\n",
    "# Utility: Daily use products should have a higher tendency to sell as compared to the \n",
    "#     specific use products.\n",
    "# Display Area: Products which are given bigger shelves in the store are likely to catch \n",
    "#     attention first and sell more.\n",
    "# Visibility in Store: The location of product in a store will impact sales. Ones which \n",
    "#     are right at entrance will catch the eye of customer first rather than the ones in back.\n",
    "# Advertising: Better advertising of products in the store will should higher sales in \n",
    "#     most cases.\n",
    "# Promotional Offers: Products accompanied with attractive offers and discounts will sell more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data might not be sufficient to test all of these, but forming these gives us a better \n",
    "# understanding of the problem and we can even look for open source information if available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start by loading the required libraries and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Read file\n",
    "train = pd.read_csv('train_data.csv')\n",
    "test = pd.read_csv('test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8523, 13) (5681, 12) (14204, 13)\n"
     ]
    }
   ],
   "source": [
    "# I will combine both train and test data sets into one, perform feature engineering and then \n",
    "# divide them later again.\n",
    "# Add a Source column to define where each observation belongs\n",
    "train['source'] = 'train'\n",
    "test['source'] = 'test'\n",
    "# Concat 2 dataframe\n",
    "data = pd.concat([train,test],ignore_index=True)\n",
    "print(train.shape, test.shape, data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier                 0\n",
       "Item_Weight                  2439\n",
       "Item_Fat_Content                0\n",
       "Item_Visibility                 0\n",
       "Item_Type                       0\n",
       "Item_MRP                        0\n",
       "Outlet_Identifier               0\n",
       "Outlet_Establishment_Year       0\n",
       "Outlet_Size                  4016\n",
       "Outlet_Location_Type            0\n",
       "Outlet_Type                     0\n",
       "Item_Outlet_Sales            5681\n",
       "source                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets start by checking which columns contain missing values.\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>11765.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>14204.000000</td>\n",
       "      <td>8523.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>12.792854</td>\n",
       "      <td>0.065953</td>\n",
       "      <td>141.004977</td>\n",
       "      <td>1997.830681</td>\n",
       "      <td>2181.288914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.652502</td>\n",
       "      <td>0.051459</td>\n",
       "      <td>62.086938</td>\n",
       "      <td>8.371664</td>\n",
       "      <td>1706.499616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.555000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.290000</td>\n",
       "      <td>1985.000000</td>\n",
       "      <td>33.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.710000</td>\n",
       "      <td>0.027036</td>\n",
       "      <td>94.012000</td>\n",
       "      <td>1987.000000</td>\n",
       "      <td>834.247400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.054021</td>\n",
       "      <td>142.247000</td>\n",
       "      <td>1999.000000</td>\n",
       "      <td>1794.331000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>16.750000</td>\n",
       "      <td>0.094037</td>\n",
       "      <td>185.855600</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>3101.296400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>21.350000</td>\n",
       "      <td>0.328391</td>\n",
       "      <td>266.888400</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>13086.964800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Item_Weight  Item_Visibility      Item_MRP  Outlet_Establishment_Year  \\\n",
       "count  11765.000000     14204.000000  14204.000000               14204.000000   \n",
       "mean      12.792854         0.065953    141.004977                1997.830681   \n",
       "std        4.652502         0.051459     62.086938                   8.371664   \n",
       "min        4.555000         0.000000     31.290000                1985.000000   \n",
       "25%        8.710000         0.027036     94.012000                1987.000000   \n",
       "50%       12.600000         0.054021    142.247000                1999.000000   \n",
       "75%       16.750000         0.094037    185.855600                2004.000000   \n",
       "max       21.350000         0.328391    266.888400                2009.000000   \n",
       "\n",
       "       Item_Outlet_Sales  \n",
       "count        8523.000000  \n",
       "mean         2181.288914  \n",
       "std          1706.499616  \n",
       "min            33.290000  \n",
       "25%           834.247400  \n",
       "50%          1794.331000  \n",
       "75%          3101.296400  \n",
       "max         13086.964800  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that the Item_Outlet_Sales is the target variable and missing values are ones in the \n",
    "# test set. So we need not worry about it. But we’ll impute the missing values in Item_Weight \n",
    "# and Outlet_Size in the data cleaning section.\n",
    "# Lets look at some basic statistics for numerical variables.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some observations:\n",
    "# 1. Item_Visibility has a min value of zero. This makes no practical sense because when a \n",
    "# product is being sold in a store, the visibility cannot be 0.\n",
    "# 2. Outlet_Establishment_Years vary from 1985 to 2009. The values might not be apt in this \n",
    "# form. Rather, if we can convert them to how old the particular store is, it should have a \n",
    "# better impact on sales.\n",
    "# 3. The lower ‘count’ of Item_Weight and Item_Outlet_Sales confirms the findings from the \n",
    "# missing value check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Item_Identifier               1559\n",
       "Item_Weight                    415\n",
       "Item_Fat_Content                 5\n",
       "Item_Visibility              13006\n",
       "Item_Type                       16\n",
       "Item_MRP                      8052\n",
       "Outlet_Identifier               10\n",
       "Outlet_Establishment_Year        9\n",
       "Outlet_Size                      3\n",
       "Outlet_Location_Type             3\n",
       "Outlet_Type                      4\n",
       "Item_Outlet_Sales             3493\n",
       "source                           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Moving to nominal (categorical) variable, lets have a look at the number of unique values \n",
    "# in each of them\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells us that there are 1559 products and 10 outlets/stores\n",
    "# Another thing that should catch attention is that Item_Type has 16 unique values\n",
    "# Let’s explore further using the frequency of different categories in each nominal variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency of Categories for varible Item_Fat_Content\n",
      "Low Fat    8485\n",
      "Regular    4824\n",
      "LF          522\n",
      "reg         195\n",
      "low fat     178\n",
      "Name: Item_Fat_Content, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible Item_Type\n",
      "Fruits and Vegetables    2013\n",
      "Snack Foods              1989\n",
      "Household                1548\n",
      "Frozen Foods             1426\n",
      "Dairy                    1136\n",
      "Baking Goods             1086\n",
      "Canned                   1084\n",
      "Health and Hygiene        858\n",
      "Meat                      736\n",
      "Soft Drinks               726\n",
      "Breads                    416\n",
      "Hard Drinks               362\n",
      "Others                    280\n",
      "Starchy Foods             269\n",
      "Breakfast                 186\n",
      "Seafood                    89\n",
      "Name: Item_Type, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible Outlet_Size\n",
      "Medium    4655\n",
      "Small     3980\n",
      "High      1553\n",
      "Name: Outlet_Size, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible Outlet_Location_Type\n",
      "Tier 3    5583\n",
      "Tier 2    4641\n",
      "Tier 1    3980\n",
      "Name: Outlet_Location_Type, dtype: int64\n",
      "\n",
      "Frequency of Categories for varible Outlet_Type\n",
      "Supermarket Type1    9294\n",
      "Grocery Store        1805\n",
      "Supermarket Type3    1559\n",
      "Supermarket Type2    1546\n",
      "Name: Outlet_Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter categorical variables\n",
    "categorical_columns = [x for x in data.dtypes.index if data.dtypes[x]=='object']\n",
    "#Exclude ID cols and source:\n",
    "categorical_columns = [x for x in categorical_columns if x not in \n",
    "                       ['Item_Identifier','Outlet_Identifier','source']]\n",
    "#Print frequency of categories\n",
    "for col in categorical_columns:\n",
    "    print('\\nFrequency of Categories for varible {}'.format(col))\n",
    "    print(data[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The output gives us following observations:\n",
    "# 1. Item_Fat_Content: Some of ‘Low Fat’ values mis-coded as ‘low fat’ and ‘LF’. Also, some of \n",
    "# ‘Regular’ are mentioned as ‘regular’.\n",
    "# 2. Item_Type: Not all categories have substantial numbers. It looks like combining them can \n",
    "# give better results.\n",
    "# 3. Outlet_Type: Supermarket Type2 and Type3 can be combined. But we should check if that’s \n",
    "# a good idea before doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orignal missing: 2439\n",
      "Final missing: 0\n"
     ]
    }
   ],
   "source": [
    "# We found two variables with missing values – Item_Weight and Outlet_Size. \n",
    "# Lets impute the former by the average weight of the particular item\n",
    "# Determine the average weight per item:\n",
    "item_avg_weight = data.pivot_table(values='Item_Weight', index='Item_Identifier')\n",
    "#Get a boolean variable specifying missing Item_Weight values\n",
    "miss_bool = data['Item_Weight'].isnull() \n",
    "#Impute data and check #missing values before and after imputation to confirm\n",
    "print('Orignal missing: {}'.format(sum(miss_bool)))\n",
    "data.loc[miss_bool,'Item_Weight'] = data.loc[miss_bool,'Item_Identifier'].apply(lambda x: item_avg_weight.loc[x,:])\n",
    "print('Final missing: {}'.format(sum(data['Item_Weight'].isnull())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This confirms that the column has no missing values now. Lets impute Outlet_Size with \n",
    "# the mode of the Outlet_Size for the particular type of outlet.\n",
    "#Import mode function:\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mode for each Outlet_Type:\n",
      "Outlet_Type Grocery Store Supermarket Type1 Supermarket Type2  \\\n",
      "Outlet_Size         Small             Small            Medium   \n",
      "\n",
      "Outlet_Type Supermarket Type3  \n",
      "Outlet_Size            Medium  \n"
     ]
    }
   ],
   "source": [
    "#Determing the mode for each\n",
    "outlet_size_mode = data.pivot_table(values='Outlet_Size', columns='Outlet_Type',\n",
    "                                    aggfunc=(lambda x:mode(x).mode[0]) )\n",
    "print('Mode for each Outlet_Type:')\n",
    "print(outlet_size_mode)\n",
    "#Get a boolean variable specifying missing Item_Weight values\n",
    "miss_bool = data['Outlet_Size'].isnull() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Orignal #missing: 4016\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#Impute data and check #missing values before and after imputation to confirm\n",
    "print('\\nOrignal #missing: {}'.format(sum(miss_bool)))\n",
    "data.loc[miss_bool,'Outlet_Size'] = data.loc[miss_bool,'Outlet_Type'].apply(lambda x: outlet_size_mode[x])\n",
    "print(sum(data['Outlet_Size'].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Grocery Store</th>\n",
       "      <td>339.828500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type1</th>\n",
       "      <td>2316.181148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type2</th>\n",
       "      <td>1995.498739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Supermarket Type3</th>\n",
       "      <td>3694.038558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Item_Outlet_Sales\n",
       "Outlet_Type                         \n",
       "Grocery Store             339.828500\n",
       "Supermarket Type1        2316.181148\n",
       "Supermarket Type2        1995.498739\n",
       "Supermarket Type3        3694.038558"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check mean sales of Supermarket Type2 and Type3 variables. If they are similar, combine them\n",
    "data.pivot_table(values='Item_Outlet_Sales',index='Outlet_Type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0 values initially: 879\n",
      "Number of 0 values after modification: 0\n"
     ]
    }
   ],
   "source": [
    "# This shows significant difference between them and we’ll leave them as it is\n",
    "# Modify Item_Visibility\n",
    "# Determine average visibility of a product\n",
    "visibility_avg = data.pivot_table(values='Item_Visibility',index='Item_Identifier')\n",
    "# Impute 0 values with mean visibility of that product:\n",
    "miss_bool = (data['Item_Visibility']==0)\n",
    "print('Number of 0 values initially: {}'.format(sum(miss_bool)))\n",
    "data.loc[miss_bool,'Item_Visibility'] = data.loc[miss_bool,'Item_Identifier'].apply(lambda x : visibility_avg.loc[x,:])\n",
    "print('Number of 0 values after modification: {}'.format((data['Item_Visibility']==0).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Food              10201\n",
       "Non-Consumable     2686\n",
       "Drink              1317\n",
       "Name: Item_Type_Combined, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a broad category of Type of Item\n",
    "# Get the first two characters of ID:\n",
    "data['Item_Type_Combined'] = data['Item_Identifier'].str[0:2]\n",
    "# Rename them to more intuitive categories:\n",
    "data['Item_Type_Combined'] = data['Item_Type_Combined'].map({'FD':'Food','DR':'Drink','NC':'Non-Consumable'})\n",
    "data['Item_Type_Combined'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14204.000000\n",
       "mean        15.169319\n",
       "std          8.371664\n",
       "min          4.000000\n",
       "25%          9.000000\n",
       "50%         14.000000\n",
       "75%         26.000000\n",
       "max         28.000000\n",
       "Name: Outlet_Years, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a new column depicting the years of operation of a store.\n",
    "data['Outlet_Years'] = 2013 - data['Outlet_Establishment_Year']\n",
    "data['Outlet_Years'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows stores which are 4-28 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categories of low fat:\n",
      "Low Fat    8485\n",
      "Regular    4824\n",
      "LF          522\n",
      "reg         195\n",
      "low fat     178\n",
      "Name: Item_Fat_Content, dtype: int64\n",
      "Categories of Fat Content after modified:\n",
      "Low Fat    9185\n",
      "Regular    5019\n",
      "Name: Item_Fat_Content, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Modify categories of Item_Fat_Content\n",
    "# Change categories of low fat:\n",
    "print('Original categories of low fat:')\n",
    "print(data['Item_Fat_Content'].value_counts())\n",
    "data['Item_Fat_Content'] = data['Item_Fat_Content'].replace({'LF':'Low Fat',\n",
    "                                                             'reg':'Regular',\n",
    "                                                             'low fat':'Low Fat'})\n",
    "print('Categories of Fat Content after modified:')\n",
    "print(data['Item_Fat_Content'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low Fat       6499\n",
       "Regular       5019\n",
       "Non-Edible    2686\n",
       "Name: Item_Fat_Content, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mark non-consumables as separate category in low_fat:\n",
    "data.loc[data['Item_Type_Combined']=='Non-Consumable','Item_Fat_Content'] = 'Non-Edible'\n",
    "data['Item_Fat_Content'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since scikit-learn accepts only numerical variables, I converted all categories of nominal variables into numeric types\n",
    "# I created a new variable ‘Outlet’ same as Outlet_Identifier and coded that\n",
    "# Outlet_Identifier should remain as it is, because it will be required in the submission file.\n",
    "# Import library:\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding all categorical variables as numeric using ‘LabelEncoder’\n",
    "le = LabelEncoder()\n",
    "# New variable for outlet\n",
    "data['Outlet'] = le.fit_transform(data['Outlet_Identifier'])\n",
    "var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']\n",
    "le = LabelEncoder()\n",
    "for i in var_mod:\n",
    "    data[i] = le.fit_transform(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One Hot Coding:\n",
    "data = pd.get_dummies(data, columns=['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Outlet_Type',\n",
    "                              'Item_Type_Combined','Outlet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Fat_Content_0</th>\n",
       "      <th>Item_Fat_Content_1</th>\n",
       "      <th>Item_Fat_Content_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Item_Fat_Content_0  Item_Fat_Content_1  Item_Fat_Content_2\n",
       "0                   1                   0                   0\n",
       "1                   0                   0                   1\n",
       "2                   1                   0                   0\n",
       "3                   0                   0                   1\n",
       "4                   0                   1                   0\n",
       "5                   0                   0                   1\n",
       "6                   0                   0                   1\n",
       "7                   1                   0                   0\n",
       "8                   0                   0                   1\n",
       "9                   0                   0                   1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['Item_Fat_Content_0','Item_Fat_Content_1','Item_Fat_Content_2']].head(10)\n",
    "# You can notice that each row will have only one of the columns as 1 corresponding to the category in the original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KETOAN\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "# Final step is to convert data back into train and test data sets\n",
    "#Drop the columns which have been converted to different types:\n",
    "data.drop(['Item_Type','Outlet_Establishment_Year'],axis=1,inplace=True)\n",
    "#Divide into test and train:\n",
    "train = data.loc[data['source']==\"train\"]\n",
    "test = data.loc[data['source']==\"test\"]\n",
    "#Drop unnecessary columns:\n",
    "test.drop(['Item_Outlet_Sales','source'],axis=1,inplace=True)\n",
    "train.drop(['source'],axis=1,inplace=True)\n",
    "#Export files as modified versions:\n",
    "train.to_csv(\"train_modified.csv\",index=False)\n",
    "test.to_csv(\"test_modified.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
